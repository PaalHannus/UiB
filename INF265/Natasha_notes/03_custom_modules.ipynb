{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Define a custom deep Neural Network in Pytorch\n",
    "\n",
    "#### Introductory note \n",
    "\n",
    "These tutorials are inspired by the book \"[Deep Learning with PyTorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf)\" by Stevens et al. They can be seen as a summary of the part I of book regarding PyTorch itself. Normally, following the tutorials should be enough and reading the book is not required. But of course, if you are interested and curious you can try to follow the book while reading these tutorials. I tried to associate the most important part of these tutorials with their respective book sections. Some other parts of the tutorials have been done from scratch or inspired by the PyTorch documentation. If you have any questions, you can ask me (Natacha), it could help me improve these tutorials and / or help other students who are struggling as much as you are. \n",
    "\n",
    "These tutorials are a \"bonus\", they are not mandatory and are not graded (there is nothing to do anyway, just read and run). They are just here to help you if you are new to PyTorch and to help you save some time by not reading the book (or at least less intensively). \n",
    "\n",
    "In short: To understand deep learning concepts, the number one priority is Andrew's course. To understand PyTorch, the priority is the documentation (always), these tutorials and if it's still not enough, don't be afraid of trying to find good tutorials on the internet, there are plenty of them and you can share them with other students (and with us) if you find some really good ones.\n",
    "\n",
    "## Contents \n",
    "\n",
    "1. Loading data, training loop and validation loop (see previous tutorial)\n",
    "2. Define a simple custom neural network\n",
    "\n",
    "  2.1 Naive (but totally ok) method  \n",
    "  2.2 Figuring out input and output shapes  \n",
    "  2.3 Using the functional API  \n",
    "  2.4 Train our custom network (as any other model)  \n",
    "  2.5 Measuring accuracy (as any other model)  \n",
    "\n",
    "3. Going deeper: defining blocks of layers\n",
    "\n",
    "  3.1 Using nn.Sequential  \n",
    "  3.2 Using a subclass of nn.Module  \n",
    "\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f94582d26d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import datetime\n",
    "\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data, training loop and validation loop (see previous tutorial)\n",
    "\n",
    "#### Loading CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Size of the training dataset:  50000\n",
      "Files already downloaded and verified\n",
      "Size of the validation dataset:  10000\n"
     ]
    }
   ],
   "source": [
    "# Where to find the data or where to download the data if not found\n",
    "data_path = 'data/'\n",
    "\n",
    "# Instantiates a dataset for the training data and downloads the data if it is not present\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    data_path,       # location from which the data will be downloaded\n",
    "    train=True,      # says whether we’re interested in the training set or the validation set\n",
    "    download=True,   # says whether we allow PyTorch to download the data if not found in 'data_path'\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "\n",
    "print('Size of the training dataset: ', len(cifar10_train))\n",
    "\n",
    "cifar10_val = datasets.CIFAR10(\n",
    "    data_path, \n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))\n",
    "print('Size of the validation dataset: ', len(cifar10_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From CIFAR-10 to CIFAR-2\n",
    "\n",
    "We define a lighter version of CIFAR-10, which is now CIFAR-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the training dataset:  10000\n",
      "Size of the validation dataset:  2000\n"
     ]
    }
   ],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "\n",
    "cifar2_train = [(img, label_map[label])\n",
    "          for img, label in cifar10_train\n",
    "          if label in [0, 2]]\n",
    "print('Size of the training dataset: ', len(cifar2_train))\n",
    "\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]\n",
    "\n",
    "print('Size of the validation dataset: ', len(cifar2_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop and validation loop on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_on_gpu(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device) \n",
    "            labels = labels.to(device=device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n",
    "\n",
    "def validate_on_gpu(model, train_loader, val_loader):\n",
    "    accdict = {}\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1)\n",
    "                total += labels.shape[0]\n",
    "                correct += int((predicted == labels).sum())\n",
    "\n",
    "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
    "        accdict[name] = correct / total\n",
    "    return accdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define a simple custom neural network\n",
    "\n",
    "### 2.1 Naive (but totally ok) method\n",
    "\n",
    "*(Inspired by 8.3.1 Our network as subclass of an nn.Module)*\n",
    "\n",
    "We saw earlier how to define a neural network using [nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential). This solution is simple and convenient but might suffer from a lack of flexibility. In order to take advantage of Pytorch's flexibility we need to define our own [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). \n",
    "\n",
    "Since most of the basic building blocks for neural networks are [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) in Pytorch, we will proceed in a similar way if we want to define a custom layer, block of layers, neural network, activation function, loss function etc. etc. It will always start by subclassing the [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) class. \n",
    "\n",
    "Let's start with a custom neural network!\n",
    "\n",
    "In order to subclass nn.Module, at a minimum we need to define a forward function that takes the inputs to the module and returns the output. This is where we define our module’s computation. With PyTorch, if we use standard torch operations, autograd will take care of the backward pass automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # to inherit the '__init__' method from the 'nn.Module' class\n",
    "        # Add whatever you want here (e.g layers and activation functions)\n",
    "        # The order and names don't matter here but it is easier to understand\n",
    "        # if you go for Layer1, activation fun, layer2, fun2, etc\n",
    "        # Some conventions:\n",
    "        # - conv stands for convolution\n",
    "        # - pool for pooling\n",
    "        # - fc for fully connected\n",
    "\n",
    "        # A few comments about the shapes are coming in the next cell\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)  \n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.act3 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    # Remember, we saw earlier that `forward` defines the \n",
    "    # computation performed at every call and that it\n",
    "    # should be overridden by all subclasses.\n",
    "    # So here we go, overidding the forward method!\n",
    "    def forward(self, x):\n",
    "        # Now the order matters! \n",
    "        # This function defines the forward pass of your neural network.\n",
    "        out = self.pool1(self.act1(self.conv1(x)))\n",
    "        out = self.pool2(self.act2(self.conv2(out)))\n",
    "        out = out.view(-1, 8 * 8 * 8) # This reshape operation was not possible when using directly nn.Sequential\n",
    "        out = self.act3(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Figuring out input and output shapes\n",
    "\n",
    "**see Andrew Ng's videos about convolution and pooling for detailed info (especially from C4W1L02 to C4W1L11) **\n",
    "\n",
    "**[Convolution](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#conv2d)**\n",
    "\n",
    "Let's recall that we are dealing with 32x32 RGB images and let's take a closer look at the following line: \n",
    "\n",
    "``nn.Conv2d(in_channels=3, out_channels16, kernel_size=3, padding=1)  ``\n",
    "\n",
    "- ``in_channels=3`` because we have 3 channels in our data (RGB). You are not free to choose whatever you want here\n",
    "- ``out_channels16`` You can put whatever you want here. Andrew refers to this number as the number of filter.\n",
    "- ``kernel_size=3`` You can put whatever you want here also. It will not really affect the shape of the output\n",
    "- ``stride=1`` (default value). THIS WILL AFFECT THE SHAPE OF YOUR OUTPUT, the greater the stride, the smaller your output image gets.\n",
    "- ``padding=1`` THIS WILL AFFECT THE SHAPE OF YOUR OUTPUT. If you choose ``padding=0`` your image will get smaller (30x30 instead of 32x32 if ``stride=1``) In order to keep the same dimension you must choose ``padding=1`` if ``stride=1``\n",
    "\n",
    "Therefore here the input shape is $(1, 3, 32, 32)$ and the output shape is $(1, 16, 32, 32)$\n",
    "\n",
    "\n",
    "**[MaxPool](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#maxpool2d)**\n",
    "\n",
    "- ``kernel_size=2`` You can put whatever you want here. It will not really affect the shape of the output\n",
    "- ``stride=kernel_size`` (default value) THIS WILL AFFECT THE SHAPE OF YOUR OUTPUT. By default ``stride=kernel_size``, as a consequence, your image size is divide by ``kernel_size``. \n",
    "\n",
    "Therefore here the input shape is $(1, 16, 32, 32)$ and the output shape is $(1, 16, 16, 16)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters:  18090\n",
      "Number of parameter per layer:  [432, 16, 1152, 8, 16384, 32, 64, 2]\n",
      "Output: \n",
      " tensor([[0.0908, 0.0938]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = MyNet()\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "print(\"Total number of parameters: \", sum(numel_list))\n",
    "print(\"Number of parameter per layer: \", numel_list)\n",
    "\n",
    "img, _ = cifar2_train[0]\n",
    "output_tensor = model(img.unsqueeze(0))\n",
    "print(\"Output: \\n\", output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Using the functional API\n",
    "*(Inspired by 8.3.3 The functional API)*\n",
    "\n",
    "We could write a more concise - but equivalent - definition of our custom network. Many things are automatically managed when using already defined [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) objects. For instance we don't need to specify the convolution operation nor what the parameters that need to be trained are nor how to train (update) them. Now some of the operations used above are let's say simpler than others. Indeed, nn.Linear and nn.Conv2d automatically instanciate trainable parameters (see [nn.parameter.Parameter](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html?highlight=parameter#torch.nn.parameter.Parameter)), link them to the network, tell the network how to do the operations, how to derive them, etc. But the nn.MaxPool2d has no associated trainable parameters and the same holds for activation functions. Modules (eg layers or activation functions) that do not generate trainable parameters can be more concisely used in Pytorch using [nn.functional](https://pytorch.org/docs/stable/nn.functional.html#torch-nn-functional) (often imported as ``F``) \n",
    "\n",
    "For example, the functional counterpart of [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d) is [nn.functional.max_pool2d](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.max_pool2d) (often imported as ``F.max_pool2d``). And the functional counterpart of [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html?highlight=relu#torch.nn.ReLU) is [relu](https://pytorch.org/docs/stable/nn.functional.html?highlight=relu#torch.nn.functional.relu) (often imported as ``F.relu``). Since ``tanh`` is a generic math function and not only used as an activation function, the counterpart of [nn.Tanh](https://pytorch.org/docs/stable/generated/torch.nn.Tanh.html#torch.nn.Tanh) is directly implemented at [torch.tanh](https://pytorch.org/docs/stable/generated/torch.tanh.html?highlight=tanh#torch.tanh)\n",
    "\n",
    "We need to keep using [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) for nn.Linear and nn.Conv2d so that our custom net will be able to manage their Parameters during training. However, we can safely switch to the functional counterparts of pooling and activation, since they have no trainable parameters. \n",
    "\n",
    "This is a lot more concise than and fully equivalent to our previous definition of CustomNet\n",
    "\n",
    "Whether to use the [functional]((https://pytorch.org/docs/stable/nn.functional.html#torch-nn-functional)) or the [modular](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) API regarding operations without trainable parameters is a decision based on style and taste. When part of a network is so simple that we want to use nn.Sequential , we're in the modular realm. When we are writing our own forwards, it may be more natural to use the functional interface for things that do not need state in the form of parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetBis(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 8, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8 * 8 * 8, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0746, -0.0411]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "img, _ = cifar2_train[0]\n",
    "model = MyNetBis()\n",
    "output_tensor = model(img.unsqueeze(0))\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Train our custom network (as any other model)\n",
    "\n",
    "On my computer training 10 epochs takes 7 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n",
      "2021-02-08 10:57:10.152071 Epoch 1, Training loss 0.5686810261504666\n",
      "2021-02-08 10:57:15.922905 Epoch 10, Training loss 0.33619848273362324\n",
      "2021-02-08 10:57:22.285335 Epoch 20, Training loss 0.298646777773359\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=64, shuffle=True)\n",
    "model = MyNetBis().to(device=device) \n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# WARNING THIS IS SUPPOSED TO MUCH MUCH FASTER THAN PREVIOUSLY BUT IT MIGHT STILL\n",
    "# TAKE A WHILE IF:\n",
    "#  - YOUR GPU IS NOT AVAILABLE\n",
    "#  - YOUR GPU IS NOT THE BEST GPU EVER. (Trying not to hurt your GPU's feeling here :) )\n",
    "# AGAIN STOP YOUR KERNEL IF IT'S TOO SLOW \n",
    "training_loop_on_gpu(\n",
    "    n_epochs = 21,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Measuring accuracy (as any other model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train: 0.87\n",
      "Accuracy val: 0.87\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2_train, batch_size=64, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
    "all_acc_dict = collections.OrderedDict()\n",
    "\n",
    "all_acc_dict[\"baseline\"] = validate_on_gpu(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Going deeper: defining blocks of layers \n",
    "\n",
    "### 3.1 Using nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output shape of conv1 will be: (1, 8, 32, 32)\n",
    "# We will use a Pooling with stride = 4 in the forward function \n",
    "# so n_in of fcblock must be: 8*(32/4)*(32/4)\n",
    "# Also n_in and n_out in nn.Linear must be consistent with each other so (n_in = n_out)\n",
    "\n",
    "class MyDeepNN(nn.Module):\n",
    "    def __init__(self, n_blocks=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=3, padding=1)\n",
    "        n_in_out = 8*8*8\n",
    "        self.fcblock = nn.Sequential(\n",
    "            *[nn.ReLU( nn.Linear(n_in_out, n_in_out) ) for _ in range(n_blocks)]\n",
    "        )\n",
    "        self.fc1 = nn.Linear(n_in_out, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 4)\n",
    "        out = out.view(-1, 8 * 8 * 8)\n",
    "        out = self.fcblock(out)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7003, 0.2633]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "Total number of parameters:  2627810\n",
      "Number of layers:  24\n",
      "Number of parameter per layer:  [216, 8, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 262144, 512, 1024, 2]\n",
      "\n",
      " MyDeepNN(\n",
      "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fcblock): Sequential(\n",
      "    (0): ReLU(\n",
      "      inplace=True\n",
      "      (inplace): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (1): ReLU(\n",
      "      inplace=True\n",
      "      (inplace): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (2): ReLU(\n",
      "      inplace=True\n",
      "      (inplace): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (3): ReLU(\n",
      "      inplace=True\n",
      "      (inplace): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (4): ReLU(\n",
      "      inplace=True\n",
      "      (inplace): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (5): ReLU(\n",
      "      inplace=True\n",
      "      (inplace): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (6): ReLU(\n",
      "      inplace=True\n",
      "      (inplace): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (7): ReLU(\n",
      "      inplace=True\n",
      "      (inplace): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (8): ReLU(\n",
      "      inplace=True\n",
      "      (inplace): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "    (9): ReLU(\n",
      "      inplace=True\n",
      "      (inplace): Linear(in_features=512, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "img, _ = cifar2_train[0]\n",
    "model = MyDeepNN(n_blocks=10)\n",
    "output_tensor = model(img.unsqueeze(0))\n",
    "print(output_tensor)\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "print(\"\\nTotal number of parameters: \", sum(numel_list))\n",
    "print(\"Number of layers: \", len(numel_list))\n",
    "print(\"Number of parameter per layer: \", numel_list)\n",
    "\n",
    "print(\"\\n\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Using a subclass of nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_in_out,\n",
    "        conv_sizes = [16, 8],\n",
    "        kernel_sizes = [3,3,3],\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # If you want to stack your blocks, the input size and the \n",
    "        # output size must be consistent, so here n_in_out\n",
    "        self.conv1 = nn.Conv2d(n_in_out, conv_sizes[0], kernel_size=kernel_sizes[0], padding=1)\n",
    "        self.conv2 = nn.Conv2d(conv_sizes[0], conv_sizes[1], kernel_size=kernel_sizes[1], padding=1)\n",
    "        self.conv3 = nn.Conv2d(conv_sizes[1], n_in_out, kernel_size=kernel_sizes[2], padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #shape = (1, n_in_out, 32, 32)\n",
    "        out = torch.tanh(self.conv1(x))\n",
    "        #shape = (1, conv_sizes[0], 32, 32)\n",
    "        out = torch.tanh(self.conv2(out))\n",
    "        #shape = (1, conv_sizes[1], 32, 32)\n",
    "        out = torch.tanh(self.conv3(out))\n",
    "        #shape = (1, n_in_out, 32, 32)\n",
    "        return out\n",
    "\n",
    "class MyDeepNN_WithMyBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_blocks=10, \n",
    "        conv_sizes=[16, 8], \n",
    "        kernel_sizes=[3,3,3]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # shape = (1, 3, 32, 32)\n",
    "        self.myblocks = nn.Sequential(\n",
    "            *[MyBlock(n_in_out=3, conv_sizes=conv_sizes, kernel_sizes=kernel_sizes) for _ in range(n_blocks)]\n",
    "        )\n",
    "        # shape = (1, n_in_out, 32, 32) but we will use maxpool with stride = 4 in the forward method so:\n",
    "        # shape = (1, n_in_out, 32/4, 32/4)\n",
    "        self.fc1 = nn.Linear(3*8*8, 2)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.myblocks(x)\n",
    "        out = F.max_pool2d(out, 4)\n",
    "        out = out.view(-1,3*8*8)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0244, 0.0096]], grad_fn=<ReluBackward0>)\n",
      "\n",
      "Total number of parameters:  55196\n",
      "Number of layers:  182\n",
      "Number of parameter per layer:  [432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 432, 16, 1152, 8, 216, 3, 384, 2]\n",
      "\n",
      " MyDeepNN_WithMyBlock(\n",
      "  (myblocks): Sequential(\n",
      "    (0): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (4): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (5): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (6): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (7): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (8): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (9): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (10): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (11): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (12): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (13): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (14): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (15): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (16): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (17): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (18): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (19): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (20): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (21): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (22): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (23): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (24): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (25): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (26): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (27): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (28): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (29): MyBlock(\n",
      "      (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(8, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (fc1): Linear(in_features=192, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "img, _ = cifar2_train[0]\n",
    "model = MyDeepNN_WithMyBlock(n_blocks=30)\n",
    "output_tensor = model(img.unsqueeze(0))\n",
    "print(output_tensor)\n",
    "\n",
    "\n",
    "numel_list = [p.numel() for p in model.parameters()]\n",
    "print(\"\\nTotal number of parameters: \", sum(numel_list))\n",
    "print(\"Number of layers: \", len(numel_list))\n",
    "print(\"Number of parameter per layer: \", numel_list)\n",
    "\n",
    "print(\"\\n\", model)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
